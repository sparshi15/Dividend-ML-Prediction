{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caebbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === STEP 1: SET FILE PATHS ===\n",
    "zip_path = \"/content/dividend_data_per_company_5 (3) (1).zip\"\n",
    "yfinance_path = \"/content/combined_stock_data.csv\"\n",
    "extract_dir = \"/content/data_dividend_extracted\"\n",
    "out_file = \"/content/ml_first_post_announcement_AugSep2025_RF_FIXED.csv\"\n",
    "\n",
    "# === STEP 2: EXTRACT ZIP ===\n",
    "if not os.path.exists(extract_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_dir)\n",
    "print(f\"âœ… Extracted ZIP to: {extract_dir}\")\n",
    "\n",
    "# === STEP 3: LOAD DIVIDEND FILES AND COMPUTE FEATURES ===\n",
    "div_rows = []\n",
    "for root, dirs, files in os.walk(extract_dir):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".csv\"):\n",
    "            full_path = os.path.join(root, f)\n",
    "            ticker_folder = os.path.basename(root)\n",
    "            df = pd.read_csv(full_path)\n",
    "            if \"Announcement Date\" not in df.columns or \"Dividend (â‚¹)\" not in df.columns:\n",
    "                continue\n",
    "            df = df[[\"Announcement Date\", \"Dividend (â‚¹)\"]].dropna()\n",
    "            df[\"ticker\"] = ticker_folder\n",
    "            df[\"announcement_date\"] = pd.to_datetime(df[\"Announcement Date\"], errors=\"coerce\")\n",
    "            df[\"div_amt\"] = df[\"Dividend (â‚¹)\"]\n",
    "            div_rows.append(df[[\"ticker\", \"announcement_date\", \"div_amt\"]])\n",
    "\n",
    "div_df = pd.concat(div_rows, ignore_index=True)\n",
    "div_df = div_df.sort_values([\"ticker\", \"announcement_date\"])\n",
    "div_df[\"log_dividend\"] = np.log1p(div_df[\"div_amt\"])\n",
    "div_df[\"mean_div_so_far\"] = (\n",
    "    div_df.groupby(\"ticker\")[\"div_amt\"].expanding().mean().shift(1).reset_index(level=0, drop=True)\n",
    ")\n",
    "div_df[\"dividend_ratio\"] = div_df.apply(\n",
    "    lambda x: 1 if pd.isna(x[\"mean_div_so_far\"]) or x[\"mean_div_so_far\"] == 0\n",
    "    else x[\"div_amt\"] / x[\"mean_div_so_far\"],\n",
    "    axis=1\n",
    ")\n",
    "print(f\"âœ… Dividend records loaded: {len(div_df)}\")\n",
    "\n",
    "# === STEP 4: LOAD YFINANCE DATA ===\n",
    "yf = pd.read_csv(yfinance_path)\n",
    "yf[\"date\"] = pd.to_datetime(yf[\"Date\"], errors=\"coerce\")\n",
    "yf[\"ticker\"] = (\n",
    "    yf[\"Symbol\"].astype(str).str.upper().str.strip()\n",
    "    if \"Symbol\" in yf.columns\n",
    "    else yf[\"Company Name\"].astype(str).str.upper().str.replace(r\"\\s+\", \"\", regex=True)\n",
    ")\n",
    "yf = yf.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "yf[\"prev_close\"] = yf.groupby(\"ticker\")[\"Close\"].shift(1)\n",
    "yf[\"return_pct\"] = (yf[\"Close\"] - yf[\"prev_close\"]) / yf[\"prev_close\"] * 100\n",
    "\n",
    "# Merge dividend features\n",
    "yf = yf.merge(\n",
    "    div_df[[\"ticker\", \"announcement_date\", \"log_dividend\", \"dividend_ratio\", \"div_amt\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"ticker\", \"date\"],\n",
    "    right_on=[\"ticker\", \"announcement_date\"]\n",
    ")\n",
    "yf[\"log_dividend\"].fillna(0, inplace=True)\n",
    "yf[\"dividend_ratio\"].fillna(1, inplace=True)\n",
    "yf[\"div_amt\"].fillna(0, inplace=True)\n",
    "\n",
    "# === STEP 5: FEATURE ENGINEERING ===\n",
    "yf[\"lag1\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).fillna(0)\n",
    "yf[\"lag2\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(2).fillna(0)\n",
    "yf[\"lag3\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(3).fillna(0)\n",
    "yf[\"vol20\"] = yf.groupby(\"ticker\")[\"return_pct\"].rolling(20).std().reset_index(0, drop=True).fillna(0)\n",
    "yf[\"momentum10\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).rolling(10).sum().reset_index(0, drop=True).fillna(0)\n",
    "\n",
    "# new stability features\n",
    "yf[\"rolling_mean_5\"] = yf.groupby(\"ticker\")[\"Close\"].transform(lambda x: x.rolling(5).mean())\n",
    "yf[\"rolling_std_5\"] = yf.groupby(\"ticker\")[\"Close\"].transform(lambda x: x.rolling(5).std())\n",
    "yf[\"price_above_ma\"] = (yf[\"Close\"] > yf[\"rolling_mean_5\"]).astype(int)\n",
    "yf[\"dividend_change\"] = yf.groupby(\"ticker\")[\"div_amt\"].diff().fillna(0)\n",
    "\n",
    "# future return target (3-day avg to reduce noise)\n",
    "yf[\"future_3d_ret\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(-1).rolling(3).mean()\n",
    "yf[\"target\"] = yf[\"future_3d_ret\"].apply(lambda x: 1 if pd.notna(x) and x >= 0 else (0 if pd.notna(x) else pd.NA))\n",
    "yf[\"isdividendday\"] = (yf[\"log_dividend\"] > 0).astype(int)\n",
    "\n",
    "features = [\n",
    "    \"lag1\", \"lag2\", \"lag3\", \"vol20\", \"momentum10\",\n",
    "    \"log_dividend\", \"dividend_ratio\",\n",
    "    \"price_above_ma\", \"dividend_change\"\n",
    "]\n",
    "\n",
    "# === STEP 6: HELPER FUNCTION ===\n",
    "def get_first_post_dividend(df, div_df_filtered):\n",
    "    rows = []\n",
    "    for tkr, sub in df.groupby(\"ticker\"):\n",
    "        sub = sub.sort_values(\"date\").reset_index(drop=True)\n",
    "        div_dates = div_df_filtered[div_df_filtered[\"ticker\"] == tkr][\"announcement_date\"]\n",
    "        for dd in div_dates:\n",
    "            candidate = sub[sub[\"date\"] > dd]\n",
    "            if not candidate.empty:\n",
    "                rows.append(candidate.iloc[[0]])\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# === STEP 7: TRAIN/TEST SPLIT ===\n",
    "train_df = get_first_post_dividend(yf, div_df[div_df[\"announcement_date\"] < \"2025-08-01\"])\n",
    "test_df = get_first_post_dividend(yf, div_df[(div_df[\"announcement_date\"] >= \"2025-08-01\") & (div_df[\"announcement_date\"] <= \"2025-09-30\")])\n",
    "train_df = train_df.dropna(subset=[\"target\"])\n",
    "test_df = test_df.dropna(subset=[\"target\"])\n",
    "X_train, y_train = train_df[features], train_df[\"target\"].astype(int)\n",
    "X_test, y_test = test_df[features], test_df[\"target\"].astype(int)\n",
    "\n",
    "# === STEP 8: SCALING & CLASS BALANCING ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
    "class_weights = {cls: w for cls, w in zip(classes, weights)}\n",
    "\n",
    "# === STEP 9: TRAIN RANDOM FOREST (with regularization) ===\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=10,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# time-based CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=tscv, scoring='f1')\n",
    "print(f\"\\nâ± TimeSeries CV F1 mean: {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# === Probability-based threshold tuning ===\n",
    "y_probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "prec, rec, thresh = precision_recall_curve(y_test, y_probs)\n",
    "f1_scores = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "best_thresh = thresh[np.argmax(f1_scores)] if len(thresh) > 0 else 0.5\n",
    "print(f\"Optimal probability threshold: {best_thresh:.3f}\")\n",
    "\n",
    "y_test_pred = (y_probs > best_thresh).astype(int)\n",
    "\n",
    "# === STEP 10: PERFORMANCE ===\n",
    "print(\"\\n=== Training Performance ===\")\n",
    "print(f\"Training F1: {f1_score(y_train, y_train_pred):.4f}\")\n",
    "print(classification_report(y_train, y_train_pred, digits=4))\n",
    "\n",
    "print(\"\\n=== Test Performance ===\")\n",
    "print(f\"Test F1: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "# === STEP 11: STRATEGY RETURNS ===\n",
    "test_df[\"ml_predicted_sign\"] = np.where(y_test_pred == 1, 1, -1)\n",
    "test_df[\"ml_strategy_return\"] = test_df[\"ml_predicted_sign\"] * test_df[\"future_3d_ret\"]\n",
    "test_df[\"oracle_strategy_return\"] = np.sign(test_df[\"future_3d_ret\"]) * test_df[\"future_3d_ret\"]\n",
    "\n",
    "ml_avg_return = test_df[\"ml_strategy_return\"].mean()\n",
    "oracle_avg_return = test_df[\"oracle_strategy_return\"].mean()\n",
    "actual_avg_return = test_df[\"future_3d_ret\"].mean()\n",
    "\n",
    "print(\"\\n=== Strategy Return Summary ===\")\n",
    "print(f\"ML strategy avg return: {ml_avg_return:.6f}\")\n",
    "print(f\"Oracle (perfect) avg return: {oracle_avg_return:.6f}\")\n",
    "print(f\"Actual avg return: {actual_avg_return:.6f}\")\n",
    "\n",
    "# === STEP 12: FEATURE IMPORTANCE ===\n",
    "imp = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "print(\"\\n=== Feature Importances ===\")\n",
    "print(imp)\n",
    "\n",
    "# === STEP 13: SAVE OUTPUT ===\n",
    "test_df[\"predicted_prob\"] = y_probs\n",
    "test_df.to_csv(out_file, index=False)\n",
    "print(f\"\\nâœ… Saved output: {out_file}\")\n",
    "print(f\"ðŸ“ Rows in output: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa855676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ======================================================\n",
    "# STEP 1: FILE PATHS\n",
    "# ======================================================\n",
    "zip_path = \"/content/dividend_data_per_company_7.zip\"\n",
    "\n",
    "#  Historical dataset (till September)\n",
    "yfinance_path = \"/content/combined_stock_data.csv\"\n",
    "\n",
    "# Dataset that contains October data\n",
    "extra_yfinance_path = \"/content/adjusted_stock_data_stripped_appended_daily_cleaned.csv\"\n",
    "\n",
    "extract_dir = \"/content/data_dividend_extracted\"\n",
    "out_file = \"/content/ml_first_post_announcement_AugOct2025_RF_FIXED.csv\"\n",
    "\n",
    "# ======================================================\n",
    "# STEP 2: EXTRACT ZIP (only once)\n",
    "# ======================================================\n",
    "if not os.path.exists(extract_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_dir)\n",
    "print(f\" Extracted ZIP to: {extract_dir}\")\n",
    "\n",
    "# ======================================================\n",
    "# STEP 3: LOAD ALL DIVIDEND FILES\n",
    "# ======================================================\n",
    "div_rows = []\n",
    "for root, dirs, files in os.walk(extract_dir):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".csv\"):\n",
    "            full_path = os.path.join(root, f)\n",
    "            ticker_folder = os.path.basename(root)\n",
    "            df = pd.read_csv(full_path)\n",
    "\n",
    "            if \"Announcement Date\" not in df.columns or \"Dividend (â‚¹)\" not in df.columns:\n",
    "                continue\n",
    "\n",
    "            df = df[[\"Announcement Date\", \"Dividend (â‚¹)\"]].dropna()\n",
    "            df[\"ticker\"] = ticker_folder\n",
    "            df[\"announcement_date\"] = pd.to_datetime(df[\"Announcement Date\"], errors=\"coerce\")\n",
    "            df[\"div_amt\"] = df[\"Dividend (â‚¹)\"]\n",
    "            div_rows.append(df[[\"ticker\", \"announcement_date\", \"div_amt\"]])\n",
    "\n",
    "div_df = pd.concat(div_rows, ignore_index=True)\n",
    "div_df = div_df.sort_values([\"ticker\", \"announcement_date\"])\n",
    "div_df[\"log_dividend\"] = np.log1p(div_df[\"div_amt\"])\n",
    "div_df[\"mean_div_so_far\"] = div_df.groupby(\"ticker\")[\"div_amt\"].expanding().mean().shift(1).reset_index(level=0, drop=True)\n",
    "div_df[\"dividend_ratio\"] = div_df.apply(lambda x: 1 if pd.isna(x[\"mean_div_so_far\"]) or x[\"mean_div_so_far\"] == 0 else x[\"div_amt\"] / x[\"mean_div_so_far\"], axis=1)\n",
    "print(f\" Dividend records loaded: {len(div_df)}\")\n",
    "\n",
    "# ======================================================\n",
    "# STEP 4: LOAD STOCK DATA (combined + October)\n",
    "# ======================================================\n",
    "yf1 = pd.read_csv(yfinance_path)\n",
    "yf2 = pd.read_csv(extra_yfinance_path)\n",
    "\n",
    "yf = pd.concat([yf1, yf2]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "yf[\"date\"] = pd.to_datetime(yf[\"Date\"], errors=\"coerce\")\n",
    "yf[\"ticker\"] = (\n",
    "    yf[\"Symbol\"].astype(str).str.upper().str.strip()\n",
    "    if \"Symbol\" in yf.columns else\n",
    "    yf[\"Company Name\"].astype(str).str.upper().str.replace(r\"\\s+\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "yf = yf.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "yf[\"prev_close\"] = yf.groupby(\"ticker\")[\"Close\"].shift(1)\n",
    "yf[\"return_pct\"] = (yf[\"Close\"] - yf[\"prev_close\"]) / yf[\"prev_close\"] * 100\n",
    "\n",
    "# merge dividend features\n",
    "yf = yf.merge(\n",
    "    div_df[[\"ticker\", \"announcement_date\", \"log_dividend\", \"dividend_ratio\", \"div_amt\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"ticker\", \"date\"],\n",
    "    right_on=[\"ticker\", \"announcement_date\"]\n",
    ")\n",
    "\n",
    "yf[\"log_dividend\"].fillna(0, inplace=True)\n",
    "yf[\"dividend_ratio\"].fillna(1, inplace=True)\n",
    "yf[\"div_amt\"].fillna(0, inplace=True)\n",
    "\n",
    "# ======================================================\n",
    "# STEP 5: FEATURE ENGINEERING\n",
    "# ======================================================\n",
    "yf[\"lag1\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).fillna(0)\n",
    "yf[\"lag2\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(2).fillna(0)\n",
    "yf[\"lag3\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(3).fillna(0)\n",
    "yf[\"vol20\"] = yf.groupby(\"ticker\")[\"return_pct\"].rolling(20).std().reset_index(0, drop=True).fillna(0)\n",
    "yf[\"momentum10\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).rolling(10).sum().reset_index(0, drop=True).fillna(0)\n",
    "\n",
    "yf[\"rolling_mean_5\"] = yf.groupby(\"ticker\")[\"Close\"].transform(lambda x: x.rolling(5).mean())\n",
    "yf[\"price_above_ma\"] = (yf[\"Close\"] > yf[\"rolling_mean_5\"]).astype(int)\n",
    "yf[\"dividend_change\"] = yf.groupby(\"ticker\")[\"div_amt\"].diff().fillna(0)\n",
    "\n",
    "yf[\"future_3d_ret\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(-1).rolling(3).mean()\n",
    "yf[\"target\"] = yf[\"future_3d_ret\"].apply(lambda x: 1 if pd.notna(x) and x >= 0 else (0 if pd.notna(x) else pd.NA))\n",
    "\n",
    "features = [\"lag1\", \"lag2\", \"lag3\", \"vol20\", \"momentum10\", \"log_dividend\", \"dividend_ratio\", \"price_above_ma\", \"dividend_change\"]\n",
    "\n",
    "# ======================================================\n",
    "# STEP 6: PICK FIRST TRADING DAY AFTER DIVIDEND ANNOUNCEMENT\n",
    "# ======================================================\n",
    "def get_first_post_dividend(df, div_df_filtered):\n",
    "    rows = []\n",
    "    for tkr, sub in df.groupby(\"ticker\"):\n",
    "        sub = sub.sort_values(\"date\").reset_index(drop=True)\n",
    "        div_dates = div_df_filtered[div_df_filtered[\"ticker\"] == tkr][\"announcement_date\"]\n",
    "        for dd in div_dates:\n",
    "            candidate = sub[sub[\"date\"] > dd]\n",
    "            if not candidate.empty:\n",
    "                rows.append(candidate.iloc[[0]])\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=df.columns)\n",
    "\n",
    "train_df = get_first_post_dividend(yf, div_df[div_df[\"announcement_date\"] < \"2025-08-01\"])\n",
    "test_df = get_first_post_dividend(yf, div_df[(div_df[\"announcement_date\"] >= \"2025-08-01\") & (div_df[\"announcement_date\"] <= \"2025-10-31\")])\n",
    "\n",
    "train_df = train_df.dropna(subset=[\"target\"])\n",
    "test_df = test_df.dropna(subset=[\"target\"])\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[\"target\"].astype(int)\n",
    "X_test, y_test = test_df[features], test_df[\"target\"].astype(int)\n",
    "\n",
    "# ======================================================\n",
    "# STEP 7: SCALE FEATURES\n",
    "# ======================================================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ======================================================\n",
    "# STEP 8: RANDOM FOREST MODEL\n",
    "# ======================================================\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=10,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=tscv, scoring='f1')\n",
    "print(f\"\\nâ± TimeSeries CV F1 mean: {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "#  TRAIN PREDICTION FIXED\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# ======================================================\n",
    "# STEP 9: TEST PREDICTIONS\n",
    "# ======================================================\n",
    "y_probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "prec, rec, thresh = precision_recall_curve(y_test, y_probs)\n",
    "f1_scores = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "best_thresh = thresh[np.argmax(f1_scores)] if len(thresh) > 0 else 0.5\n",
    "\n",
    "y_test_pred = (y_probs > best_thresh).astype(int)\n",
    "\n",
    "print(\"\\n=== Training Performance ===\")\n",
    "print(f\"Training F1: {f1_score(y_train, y_train_pred):.4f}\")\n",
    "print(classification_report(y_train, y_train_pred, digits=4))\n",
    "\n",
    "print(\"\\n=== Test Performance ===\")\n",
    "print(f\"Test F1: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "# ======================================================\n",
    "# STEP 11: STRATEGY RETURNS (COMPARE WITH PERFECT ORACLE)\n",
    "# ======================================================\n",
    "test_df[\"ml_predicted_sign\"] = np.where(y_test_pred == 1, 1, -1)\n",
    "test_df[\"ml_strategy_return\"] = test_df[\"ml_predicted_sign\"] * test_df[\"future_3d_ret\"]\n",
    "test_df[\"oracle_strategy_return\"] = np.sign(test_df[\"future_3d_ret\"]) * test_df[\"future_3d_ret\"]\n",
    "\n",
    "ml_avg_return = test_df[\"ml_strategy_return\"].mean()\n",
    "oracle_avg_return = test_df[\"oracle_strategy_return\"].mean()\n",
    "actual_avg_return = test_df[\"future_3d_ret\"].mean()\n",
    "\n",
    "print(\"\\n=== Strategy Return Summary ===\")\n",
    "print(f\"ML Strategy avg return: {ml_avg_return:.6f}\")\n",
    "print(f\"Oracle (perfect) avg return: {oracle_avg_return:.6f}\")\n",
    "print(f\"Actual avg return: {actual_avg_return:.6f}\")\n",
    "\n",
    "# ======================================================\n",
    "# STEP 12: FEATURE IMPORTANCE\n",
    "# ======================================================\n",
    "imp = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "print(\"\\n=== Feature Importances ===\")\n",
    "print(imp)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# STEP 10: SAVE OUTPUT\n",
    "# ======================================================\n",
    "test_df[\"predicted_prob\"] = y_probs\n",
    "test_df.to_csv(out_file, index=False)\n",
    "\n",
    "print(\"\\n Output updated (INCLUDING OCTOBER DATA)\")\n",
    "print(f\" Saved to: {out_file}\")\n",
    "print(f\" Test rows = {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92ebc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
