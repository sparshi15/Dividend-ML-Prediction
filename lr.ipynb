{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15781d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === STEP 1: SET FILE PATHS ===\n",
    "zip_path = \"/content/dividend_data_per_company_5 (3) (1).zip\"\n",
    "yfinance_path = \"/content/combined_stock_data.csv\"\n",
    "extract_dir = \"/content/data_dividend_extracted\"\n",
    "out_file = \"/content/ml_first_post_announcement_AugSep2025_LR_BESTFEAT.csv\"\n",
    "\n",
    "# === STEP 2: EXTRACT ZIP ===\n",
    "if not os.path.exists(extract_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_dir)\n",
    "print(f\"âœ… Extracted ZIP to: {extract_dir}\")\n",
    "\n",
    "# === STEP 3: LOAD DIVIDEND FILES AND COMPUTE FEATURES ===\n",
    "div_rows = []\n",
    "for root, dirs, files in os.walk(extract_dir):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".csv\"):\n",
    "            full_path = os.path.join(root, f)\n",
    "            ticker_folder = os.path.basename(root)\n",
    "            df = pd.read_csv(full_path)\n",
    "            if \"Announcement Date\" not in df.columns or \"Dividend (â‚¹)\" not in df.columns:\n",
    "                continue\n",
    "            df = df[[\"Announcement Date\", \"Dividend (â‚¹)\"]].dropna()\n",
    "            df[\"ticker\"] = ticker_folder\n",
    "            df[\"announcement_date\"] = pd.to_datetime(df[\"Announcement Date\"], errors=\"coerce\")\n",
    "            df[\"div_amt\"] = df[\"Dividend (â‚¹)\"]\n",
    "            div_rows.append(df[[\"ticker\", \"announcement_date\", \"div_amt\"]])\n",
    "\n",
    "div_df = pd.concat(div_rows, ignore_index=True)\n",
    "div_df = div_df.sort_values([\"ticker\", \"announcement_date\"])\n",
    "div_df[\"log_dividend\"] = np.log1p(div_df[\"div_amt\"])\n",
    "div_df[\"mean_div_so_far\"] = (\n",
    "    div_df.groupby(\"ticker\")[\"div_amt\"].expanding().mean().shift(1).reset_index(level=0, drop=True)\n",
    ")\n",
    "div_df[\"dividend_ratio\"] = div_df.apply(\n",
    "    lambda x: 1 if pd.isna(x[\"mean_div_so_far\"]) or x[\"mean_div_so_far\"] == 0\n",
    "    else x[\"div_amt\"] / x[\"mean_div_so_far\"],\n",
    "    axis=1\n",
    ")\n",
    "print(f\"âœ… Dividend records loaded: {len(div_df)}\")\n",
    "\n",
    "# === STEP 4: LOAD YFINANCE DATA ===\n",
    "yf = pd.read_csv(yfinance_path)\n",
    "yf[\"date\"] = pd.to_datetime(yf[\"Date\"], errors=\"coerce\")\n",
    "yf[\"ticker\"] = (\n",
    "    yf[\"Symbol\"].astype(str).str.upper().str.strip()\n",
    "    if \"Symbol\" in yf.columns\n",
    "    else yf[\"Company Name\"].astype(str).str.upper().str.replace(r\"\\s+\", \"\", regex=True)\n",
    ")\n",
    "yf = yf.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "yf[\"prev_close\"] = yf.groupby(\"ticker\")[\"Close\"].shift(1)\n",
    "yf[\"return_pct\"] = (yf[\"Close\"] - yf[\"prev_close\"]) / yf[\"prev_close\"] * 100\n",
    "\n",
    "# Merge dividend features\n",
    "yf = yf.merge(\n",
    "    div_df[[\"ticker\", \"announcement_date\", \"log_dividend\", \"dividend_ratio\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"ticker\", \"date\"],\n",
    "    right_on=[\"ticker\", \"announcement_date\"]\n",
    ")\n",
    "yf[\"log_dividend\"].fillna(0, inplace=True)\n",
    "yf[\"dividend_ratio\"].fillna(1, inplace=True)\n",
    "\n",
    "# === STEP 5: FEATURE ENGINEERING ===\n",
    "yf[\"lag1\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).fillna(0)\n",
    "yf[\"lag2\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(2).fillna(0)\n",
    "yf[\"lag3\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(3).fillna(0)\n",
    "yf[\"lag5\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).rolling(5).mean().reset_index(0, drop=True).fillna(0)\n",
    "yf[\"lag10\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).rolling(10).mean().reset_index(0, drop=True).fillna(0)\n",
    "yf[\"vol20\"] = yf.groupby(\"ticker\")[\"return_pct\"].rolling(20).std().reset_index(0, drop=True).fillna(0)\n",
    "yf[\"momentum10\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).rolling(10).sum().reset_index(0, drop=True).fillna(0)\n",
    "\n",
    "yf[\"return_next\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(-1)\n",
    "yf[\"target\"] = yf[\"return_next\"].apply(lambda x: 1 if pd.notna(x) and x >= 0 else (0 if pd.notna(x) else pd.NA))\n",
    "yf[\"isdividendday\"] = (yf[\"log_dividend\"] > 0).astype(int)\n",
    "yf[\"nonannouncement\"] = (yf[\"isdividendday\"] == 0).astype(int)\n",
    "\n",
    "# === CHOOSE BEST FEATURE COMBO (based on earlier tests) ===\n",
    "features = [\"lag1\", \"lag2\", \"lag3\", \"vol20\", \"log_dividend\", \"dividend_ratio\"]\n",
    "\n",
    "# === STEP 6: HELPER FUNCTION ===\n",
    "def get_first_post_dividend(df, div_df_filtered):\n",
    "    rows = []\n",
    "    for tkr, sub in df.groupby(\"ticker\"):\n",
    "        sub = sub.sort_values(\"date\").reset_index(drop=True)\n",
    "        div_dates = div_df_filtered[div_df_filtered[\"ticker\"] == tkr][\"announcement_date\"]\n",
    "        for dd in div_dates:\n",
    "            candidate = sub[sub[\"date\"] > dd]\n",
    "            if not candidate.empty:\n",
    "                rows.append(candidate.iloc[[0]])\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# === STEP 7: TRAIN/TEST SPLIT ===\n",
    "train_df = get_first_post_dividend(yf, div_df[div_df[\"announcement_date\"] < \"2025-08-01\"])\n",
    "test_df = get_first_post_dividend(yf, div_df[(div_df[\"announcement_date\"] >= \"2025-08-01\") & (div_df[\"announcement_date\"] <= \"2025-09-30\")])\n",
    "train_df = train_df.dropna(subset=[\"target\"])\n",
    "test_df = test_df.dropna(subset=[\"target\"])\n",
    "X_train, y_train = train_df[features], train_df[\"target\"].astype(int)\n",
    "X_test, y_test = test_df[features], test_df[\"target\"].astype(int)\n",
    "\n",
    "# === STEP 8: SCALING & CLASS BALANCING ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Compute class weights to handle imbalance\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
    "class_weights = {cls: w for cls, w in zip(classes, weights)}\n",
    "\n",
    "# === STEP 9: TRAIN LOGISTIC REGRESSION ===\n",
    "model = LogisticRegression(max_iter=1000, random_state=42, class_weight=class_weights)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== Training Performance ===\")\n",
    "print(f\"Training F1: {f1_score(y_train, y_train_pred):.4f}\")\n",
    "print(classification_report(y_train, y_train_pred, digits=4))\n",
    "\n",
    "print(\"\\n=== Test Performance ===\")\n",
    "print(f\"Test F1: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "# === STEP 10: STRATEGY RETURNS ===\n",
    "test_df[\"ml_predicted_sign\"] = [1 if p >= 0.5 else -1 for p in model.predict_proba(X_test_scaled)[:, 1]]\n",
    "test_df[\"ml_strategy_return\"] = test_df[\"ml_predicted_sign\"] * test_df[\"return_next\"]\n",
    "test_df[\"oracle_strategy_return\"] = np.sign(test_df[\"return_next\"]) * test_df[\"return_next\"]\n",
    "\n",
    "ml_avg_return = test_df[\"ml_strategy_return\"].mean()\n",
    "oracle_avg_return = test_df[\"oracle_strategy_return\"].mean()\n",
    "actual_avg_return = test_df[\"return_next\"].mean()\n",
    "\n",
    "print(\"\\n=== Strategy Return Summary ===\")\n",
    "print(f\"ML strategy avg return: {ml_avg_return:.6f}\")\n",
    "print(f\"Oracle (perfect) avg return: {oracle_avg_return:.6f}\")\n",
    "print(f\"Actual avg return: {actual_avg_return:.6f}\")\n",
    "\n",
    "# === STEP 11: SAVE RESULTS ===\n",
    "test_df.to_csv(out_file, index=False)\n",
    "print(f\"\\nâœ… Saved output: {out_file}\")\n",
    "print(f\"ðŸ“ Rows in output: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ======================================================\n",
    "# STEP 1: FILE PATHS\n",
    "# ======================================================\n",
    "zip_path = \"/content/dividend_data_per_company_7.zip\"\n",
    "\n",
    "# âœ… historical dataset\n",
    "yfinance_path = \"/content/combined_stock_data.csv\"\n",
    "\n",
    "# âœ… October extended dataset\n",
    "extra_yfinance_path = \"/content/adjusted_stock_data_stripped_appended_daily_cleaned.csv\"\n",
    "\n",
    "extract_dir = \"/content/data_dividend_extracted\"\n",
    "out_file = \"/content/ml_first_post_announcement_AugOct2025_LR_FIXED.csv\"\n",
    "\n",
    "# ======================================================\n",
    "# STEP 2: EXTRACT ZIP (only once)\n",
    "# ======================================================\n",
    "if not os.path.exists(extract_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_dir)\n",
    "print(f\"âœ… Extracted ZIP to: {extract_dir}\")\n",
    "\n",
    "# ======================================================\n",
    "# STEP 3: LOAD DIVIDEND DATA\n",
    "# ======================================================\n",
    "div_rows = []\n",
    "for root, dirs, files in os.walk(extract_dir):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".csv\"):\n",
    "            full_path = os.path.join(root, f)\n",
    "            ticker_folder = os.path.basename(root)\n",
    "            df = pd.read_csv(full_path)\n",
    "\n",
    "            if \"Announcement Date\" not in df.columns or \"Dividend (â‚¹)\" not in df.columns:\n",
    "                continue\n",
    "\n",
    "            df = df[[\"Announcement Date\", \"Dividend (â‚¹)\"]].dropna()\n",
    "            df[\"ticker\"] = ticker_folder\n",
    "            df[\"announcement_date\"] = pd.to_datetime(df[\"Announcement Date\"], errors=\"coerce\")\n",
    "            df[\"div_amt\"] = df[\"Dividend (â‚¹)\"]\n",
    "            div_rows.append(df[[\"ticker\", \"announcement_date\", \"div_amt\"]])\n",
    "\n",
    "div_df = pd.concat(div_rows, ignore_index=True)\n",
    "div_df = div_df.sort_values([\"ticker\", \"announcement_date\"])\n",
    "div_df[\"log_dividend\"] = np.log1p(div_df[\"div_amt\"])\n",
    "div_df[\"mean_div_so_far\"] = div_df.groupby(\"ticker\")[\"div_amt\"].expanding().mean().shift(1).reset_index(level=0, drop=True)\n",
    "div_df[\"dividend_ratio\"] = div_df.apply(lambda x: 1 if pd.isna(x[\"mean_div_so_far\"]) or x[\"mean_div_so_far\"] == 0 else x[\"div_amt\"] / x[\"mean_div_so_far\"], axis=1)\n",
    "\n",
    "print(f\"âœ… Dividend records loaded: {len(div_df)}\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# STEP 4: LOAD STOCK DATA (combined + October)\n",
    "# ======================================================\n",
    "yf1 = pd.read_csv(yfinance_path)\n",
    "yf2 = pd.read_csv(extra_yfinance_path)\n",
    "\n",
    "yf = pd.concat([yf1, yf2]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "yf[\"date\"] = pd.to_datetime(yf[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "yf[\"ticker\"] = (\n",
    "    yf[\"Symbol\"].astype(str).str.upper().str.strip()\n",
    "    if \"Symbol\" in yf.columns else\n",
    "    yf[\"Company Name\"].astype(str).str.upper().str.replace(r\"\\s+\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "yf = yf.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "yf[\"prev_close\"] = yf.groupby(\"ticker\")[\"Close\"].shift(1)\n",
    "yf[\"return_pct\"] = (yf[\"Close\"] - yf[\"prev_close\"]) / yf[\"prev_close\"] * 100\n",
    "\n",
    "# Merge dividend features\n",
    "yf = yf.merge(\n",
    "    div_df[[\"ticker\", \"announcement_date\", \"log_dividend\", \"dividend_ratio\", \"div_amt\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"ticker\", \"date\"],\n",
    "    right_on=[\"ticker\", \"announcement_date\"]\n",
    ")\n",
    "\n",
    "yf[\"log_dividend\"].fillna(0, inplace=True)\n",
    "yf[\"dividend_ratio\"].fillna(1, inplace=True)\n",
    "yf[\"div_amt\"].fillna(0, inplace=True)\n",
    "\n",
    "# ======================================================\n",
    "# STEP 5: FEATURE ENGINEERING\n",
    "# ======================================================\n",
    "yf[\"lag1\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).fillna(0)\n",
    "yf[\"lag2\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(2).fillna(0)\n",
    "yf[\"lag3\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(3).fillna(0)\n",
    "yf[\"vol20\"] = yf.groupby(\"ticker\")[\"return_pct\"].rolling(20).std().reset_index(0, drop=True).fillna(0)\n",
    "yf[\"momentum10\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(1).rolling(10).sum().reset_index(0, drop=True).fillna(0)\n",
    "yf[\"rolling_mean_5\"] = yf.groupby(\"ticker\")[\"Close\"].transform(lambda x: x.rolling(5).mean())\n",
    "yf[\"price_above_ma\"] = (yf[\"Close\"] > yf[\"rolling_mean_5\"]).astype(int)\n",
    "yf[\"dividend_change\"] = yf.groupby(\"ticker\")[\"div_amt\"].diff().fillna(0)\n",
    "\n",
    "# target = future 3-day average return sign\n",
    "yf[\"future_3d_ret\"] = yf.groupby(\"ticker\")[\"return_pct\"].shift(-1).rolling(3).mean()\n",
    "yf[\"target\"] = yf[\"future_3d_ret\"].apply(lambda x: 1 if pd.notna(x) and x >= 0 else (0 if pd.notna(x) else pd.NA))\n",
    "\n",
    "features = [\"lag1\", \"lag2\", \"lag3\", \"vol20\", \"momentum10\", \"log_dividend\", \"dividend_ratio\", \"price_above_ma\", \"dividend_change\"]\n",
    "\n",
    "# ======================================================\n",
    "# STEP 6: TAKE FIRST POST-ANNOUNCEMENT TRADING DAY\n",
    "# ======================================================\n",
    "def get_first_post_dividend(df, div_df_filtered):\n",
    "    rows = []\n",
    "    for tkr, sub in df.groupby(\"ticker\"):\n",
    "        sub = sub.sort_values(\"date\").reset_index(drop=True)\n",
    "        div_dates = div_df_filtered[div_df_filtered[\"ticker\"] == tkr][\"announcement_date\"]\n",
    "        for dd in div_dates:\n",
    "            candidate = sub[sub[\"date\"] > dd]\n",
    "            if not candidate.empty:\n",
    "                rows.append(candidate.iloc[[0]])\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=df.columns)\n",
    "\n",
    "train_df = get_first_post_dividend(yf, div_df[div_df[\"announcement_date\"] < \"2025-08-01\"])\n",
    "test_df  = get_first_post_dividend(yf, div_df[(div_df[\"announcement_date\"] >= \"2025-08-01\") & (div_df[\"announcement_date\"] <= \"2025-10-31\")])\n",
    "\n",
    "train_df = train_df.dropna(subset=[\"target\"])\n",
    "test_df = test_df.dropna(subset=[\"target\"])\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[\"target\"].astype(int)\n",
    "X_test,  y_test  = test_df[features],  test_df[\"target\"].astype(int)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# STEP 7: SCALE FEATURES\n",
    "# ======================================================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# STEP 8: LOGISTIC REGRESSION MODEL\n",
    "# ======================================================\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {cls: w for cls, w in zip(np.unique(y_train), class_weights)}\n",
    "\n",
    "model = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=class_weights,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=tscv, scoring='f1')\n",
    "print(f\"\\nâ± TimeSeries CV F1 mean: {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "prec, rec, thresh = precision_recall_curve(y_test, y_probs)\n",
    "f1_scores = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "best_thresh = thresh[np.argmax(f1_scores)] if len(thresh) > 0 else 0.5\n",
    "\n",
    "y_test_pred = (y_probs > best_thresh).astype(int)\n",
    "\n",
    "# ======================================================\n",
    "# STEP 9: REPORT METRICS\n",
    "# ======================================================\n",
    "print(\"\\n=== Training Performance ===\")\n",
    "print(classification_report(y_train, model.predict(X_train_scaled), digits=4))\n",
    "\n",
    "print(\"\\n=== Test Performance ===\")\n",
    "print(f\"Test F1: {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# STEP 10: STRATEGY RETURNS\n",
    "# ======================================================\n",
    "test_df[\"ml_predicted_sign\"] = np.where(y_test_pred == 1, 1, -1)\n",
    "test_df[\"ml_strategy_return\"] = test_df[\"ml_predicted_sign\"] * test_df[\"future_3d_ret\"]\n",
    "test_df[\"oracle_strategy_return\"] = np.sign(test_df[\"future_3d_ret\"]) * test_df[\"future_3d_ret\"]\n",
    "\n",
    "print(\"\\n=== Strategy Return Summary ===\")\n",
    "print(f\"ML Strategy avg return: {test_df['ml_strategy_return'].mean():.6f}\")\n",
    "print(f\"Oracle avg return: {test_df['oracle_strategy_return'].mean():.6f}\")\n",
    "print(f\"Actual avg return: {test_df['future_3d_ret'].mean():.6f}\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# STEP 11: SAVE OUTPUT\n",
    "# ======================================================\n",
    "test_df[\"predicted_prob\"] = y_probs\n",
    "test_df.to_csv(out_file, index=False)\n",
    "\n",
    "print(\"\\nâœ… Logistic Regression version UPDATED (with October data)\")\n",
    "print(f\"ðŸ‘‰ Output saved to: {out_file}\")\n",
    "print(f\"ðŸ“Œ Test rows = {len(test_df)}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
